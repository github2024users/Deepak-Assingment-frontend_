# Frontend - Web Scraper Portal

React-based frontend for the Web Scraper Portal with Google OAuth authentication.

## ğŸ“‹ Requirements

- **Node.js** 14+ 
- **npm** 6+
- **Modern browser** (Chrome, Firefox, Safari, Edge)
- **Google OAuth Client ID**

## ğŸ”‘ Google OAuth Setup

### Step 1: Create OAuth Client ID

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select existing one
3. Go to **Credentials** â†’ **Create Credentials** â†’ **OAuth Client ID**
4. Choose **Web application**
5. Add authorized origins:
   - `http://localhost:3000`
6. Add authorized redirect URIs:
   - `http://localhost:3000`
7. Copy the **Client ID**


### Step 2: Create .env File

Create `frontend/.env` file:

```
REACT_APP_GOOGLE_CLIENT_ID=your_client_id_here
REACT_APP_API_URL=http://localhost:5000
```

NOTE: if .env file already exists then no need to create the file. Just paste your client id without any quotation

for example:
REACT_APP_GOOGLE_CLIENT_ID=1025812354080-sjvmd62okhe0qskmhs3dhe65gjk8jmvic.apps.googleusercontent.com (don't use it as client id, it's only for example, it doesn't exists)


Replace `your_client_id_here` with your actual Google Client ID.

## ğŸš€ Installation

```bash or terminal
# Navigate to frontend folder
cd frontend

# Install dependencies
npm install

# Start development server
npm start
```

Frontend will open at: http://localhost:3000

## ğŸ“ Project Structure

```
frontend/
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html              # HTML entry point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Login.js            # Google OAuth login component
â”‚   â”‚   â””â”€â”€ Dashboard.js        # Main dashboard & scraping interface
â”‚   â”œâ”€â”€ App.js                  # Main app component with routing
â”‚   â”œâ”€â”€ App.css                 # Global styles
â”‚   â”œâ”€â”€ index.js                # React DOM render
â”‚   â””â”€â”€ index.html              # HTML template
â”œâ”€â”€ package.json                # Dependencies & scripts
â”œâ”€â”€ .env                        # Environment variables
â””â”€â”€ README.md                   # This file
```

## ğŸ¯ Components

### App.js
Main component that handles:
- Google OAuth provider setup
- User authentication state
- Routing between Login and Dashboard
- Session persistence

```javascript
<GoogleOAuthProvider clientId={GOOGLE_CLIENT_ID}>
  {!user ? <Login /> : <Dashboard user={user} />}
</GoogleOAuthProvider>
```

### Login.js
- Google OAuth login button
- Handles authentication flow
- Fetches user profile information
- Stores user data

### Dashboard.js
- Main scraping interface
- URL input and button controls
- Data display with categorization
- Refresh and Clear All functionality
- Error/success notifications

## ğŸ¨ Styling

### Colors Used
- **Primary Blue:** `#0d6efd`
- **Success Green:** `#28a745`
- **Warning Yellow:** `#ffc107`
- **Danger Red:** `#ff0000`
- **Gray:** `#6c757d`

### Category Colors
- AI: `#0066FF` (Blue)
- Tech: `#FF6600` (Orange)
- Startups: `#FF1493` (Pink)
- Tutorials: `#00AA00` (Green)
- Open Source: `#9900FF` (Purple)
- Programming: `#FF9900` (Orange)
- Web: `#00CCCC` (Cyan)
- Security: `#FF0000` (Red)
- Jobs: `#6B48A8` (Purple)
- Other: `#666666` (Gray)

## ğŸ“ Key Features

### OAuth Authentication
```javascript
const login = useGoogleLogin({
  onSuccess: tokenResponse => {
    // Fetch user info and set state
  },
  scope: 'openid profile email'
});
```

### Dynamic URL Scraping
```javascript
const backendUrl = 'http://localhost:5000/scrape?url=' + encodeURIComponent(url);
const response = await fetch(backendUrl);
```

### Data Categorization
Data is automatically categorized into 9 categories:
- AI, Tech, Startups, Tutorials, Open Source, Programming, Web, Security, Jobs

### Data Persistence
- Uses **localStorage** for data backup
- Saves user session
- Persists across page reloads

### Notifications
- **Errors:** Auto-hide after 10 seconds
- **Success:** Auto-hide after 5 seconds
- User can manually close notifications

### Button Controls
- **Scrape URL:** Fresh data from entered URL
  - Triggered by Enter key or clicking button
  - Disables Refresh during execution
  - Shows darker blue when active

- **Refresh:** Merge or fetch new data
  - Only triggered by clicking button
  - Disables Scrape URL during execution
  - Shows darker green when active

## ğŸ”§ Configuration

### package.json Scripts

```json
{
  "scripts": {
    "start": "react-scripts start",      // Start dev server
    "build": "react-scripts build",      // Build for production
    "test": "react-scripts test"         // Run tests
  }
}
```

### Environment Variables

| Variable | Description | Example |
|----------|-------------|---------|
| `REACT_APP_GOOGLE_CLIENT_ID` | Google OAuth Client ID | `123456789.apps.googleusercontent.com` |
| `REACT_APP_API_URL` | Backend API URL | `http://localhost:5000` |

## ğŸ§ª Testing

### Manual Testing

1. **Login**
   ```
   - Click "Sign in with Google"
   - Complete OAuth flow
   - Should see dashboard
   ```

2. **Scraping**
   ```
   - Enter: news.ycombinator.com
   - Click "Scrape URL" or press Enter
   - Wait for data to load
   - See categorized results
   ```

3. **Button Independence**
   ```
   - Click Scrape URL â†’ Refresh grays out
   - Click Refresh â†’ Scrape URL grays out
   - Enter key â†’ Only Scrape URL works
   ```

4. **Notifications**
   ```
   - Invalid URL â†’ Error shows for 10s
   - Valid URL â†’ Success shows for 5s
   ```

5. **Persistence**
   ```
   - Scrape data
   - Refresh page (Ctrl+R)
   - Data still visible
   - User still logged in
   ```

## ğŸ“¦ Dependencies

```json
{
  "react": "^18.2.0",
  "react-dom": "^18.2.0",
  "react-scripts": "5.0.1",
  "@react-oauth/google": "^0.7.0"
}
```

### Installation
```bash
npm install
```

## ğŸš€ Production Build

```bash
# Create optimized production build
npm run build

# Build folder is ready to deploy
# Can be deployed to Vercel, Netlify, etc.
```

## ğŸ”’ Security

- âœ… OAuth token handled securely
- âœ… No passwords stored in browser
- âœ… CORS requests to backend
- âœ… localStorage for non-sensitive data only
- âœ… User Agent spoofing for ethical scraping

## ğŸ› Troubleshooting

### OAuth not working
- **Check:** Google Client ID in `.env`
- **Check:** Authorized origins in Google Console
- **Fix:** Clear cookies and try again

### Backend connection error
- **Check:** Backend is running on port 5000
- **Check:** `REACT_APP_API_URL` is correct
- **Check:** CORS is enabled on backend

### Data not showing
- **Check:** Website is accessible
- **Check:** Backend is running
- **Check:** Check browser console for errors

### Button states not changing
- Hard refresh page (Ctrl+Shift+R)
- Clear browser cache
- Check React DevTools

## ğŸ“š Code Examples

### Scraping a Website
```javascript
const handleScrapeOnly = async () => {
  setActiveButton('scrape');
  
  const url = 'https://news.ycombinator.com';
  const response = await fetch(
    'http://localhost:5000/scrape?url=' + encodeURIComponent(url)
  );
  const data = await response.json();
  
  setData(data);
  setActiveButton(null);
};
```

### Handling Notifications
```javascript
// Auto-hide errors after 10 seconds
useEffect(() => {
  if (error) {
    const timer = setTimeout(() => setError(null), 10000);
    return () => clearTimeout(timer);
  }
}, [error]);
```

### localStorage Usage
```javascript
// Save data
localStorage.setItem('scraper_data', JSON.stringify(data));

// Load data
const savedData = localStorage.getItem('scraper_data');
```

## ğŸš¢ Deployment

### Deploy to Vercel
```bash
npm run build
# Deploy 'build' folder to Vercel
```

### Deploy to Netlify
```bash
npm run build
# Deploy 'build' folder to Netlify
```

### Environment Variables for Production
Update `.env.production`:
```
REACT_APP_GOOGLE_CLIENT_ID=your_production_client_id
REACT_APP_API_URL=https://your-backend-url.com
```

## ğŸ“ Support

For issues:
1. Check console logs (F12)
2. See Troubleshooting section
3. Verify configuration files
4. Check main README.md

---#   D e e p a k - A s s i n g m e n t - f r o n t e n d _  
 